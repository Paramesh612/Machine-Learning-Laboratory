{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec960ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>student</th>\n",
       "      <th>credit_rating</th>\n",
       "      <th>buys_computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youth</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youth</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle_aged</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senior</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senior</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  income student credit_rating buys_computer\n",
       "0        youth    high      no          fair            no\n",
       "1        youth    high      no     excellent            no\n",
       "2  middle_aged    high      no          fair           yes\n",
       "3       senior  medium      no          fair           yes\n",
       "4       senior     low     yes          fair           yes"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #for manipulating the csv data\n",
    "import numpy as np #for mathematical calculation\n",
    "\n",
    "train_data_m = pd.read_excel(\"input.xlsx\") #importing the dataset from the disk\n",
    "train_data_m.head() #viewing some row of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b03843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: #for each class in the label\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
    "    \n",
    "    return total_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28759b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928159a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509dec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label)  # features excluding the label\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    for feature in feature_list:\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        print(f\"Feature: {feature}, Info Gain: {feature_info_gain}\")  # This will show info gain for each feature\n",
    "        if max_info_gain < feature_info_gain:\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55879465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.items():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
    "        \n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
    "\n",
    "            if class_count == count: #count of (feature_value = count) of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further, \n",
    "                                      #so the branch is marking with ?\n",
    "            \n",
    "    return tree, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830f1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a5ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c086596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: age, Info Gain: 0.24674981977443933\n",
      "Feature: income, Info Gain: 0.02922256565895487\n",
      "Feature: student, Info Gain: 0.15183550136234159\n",
      "Feature: credit_rating, Info Gain: 0.04812703040826949\n",
      "Feature: age, Info Gain: 0.0\n",
      "Feature: income, Info Gain: 0.5709505944546686\n",
      "Feature: student, Info Gain: 0.9709505944546686\n",
      "Feature: credit_rating, Info Gain: 0.01997309402197489\n",
      "Feature: age, Info Gain: 0.0\n",
      "Feature: income, Info Gain: 0.01997309402197489\n",
      "Feature: student, Info Gain: 0.01997309402197489\n",
      "Feature: credit_rating, Info Gain: 0.9709505944546686\n",
      "{'age': {'youth': {'student': {'no': 'no', 'yes': 'yes'}}, 'middle_aged': 'yes', 'senior': {'credit_rating': {'fair': 'yes', 'excellent': 'no'}}}}\n"
     ]
    }
   ],
   "source": [
    "tree = id3(train_data_m, 'buys_computer')\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697df28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART- GINI INDEX\n"
     ]
    }
   ],
   "source": [
    "print(\"CART- GINI INDEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d60ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(data, label):\n",
    "    class_counts = data[label].value_counts()  # count occurrences of each class\n",
    "    total = len(data)  # total number of rows\n",
    "    gini = 1.0\n",
    "    \n",
    "    for count in class_counts:\n",
    "        prob = count / total  # probability of a class\n",
    "        gini -= prob ** 2  # subtract squared probability from 1\n",
    "    \n",
    "    return gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c410db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini_split(data, feature_name, label):\n",
    "    feature_values = data[feature_name].unique()  # unique values for the feature\n",
    "    total = len(data)  # total number of rows\n",
    "    gini_split = 0.0\n",
    "\n",
    "    for value in feature_values:\n",
    "        # Subset data where feature_name == value\n",
    "        subset = data[data[feature_name] == value]\n",
    "        gini_value = calc_gini(subset, label)  # Gini of this subset\n",
    "        weight = len(subset) / total  # weight based on subset size\n",
    "        gini_split += weight * gini_value  # add weighted Gini of this subset\n",
    "\n",
    "    return gini_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1790c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, label):\n",
    "    feature_list = data.columns.drop(label)  # list of features excluding the label\n",
    "    best_gini = float('inf')  # start with a very high Gini\n",
    "    best_feature = None\n",
    "\n",
    "    for feature in feature_list:\n",
    "        gini_split = calc_gini_split(data, feature, label)\n",
    "        print(f\"Feature: {feature}, Gini: {gini_split}\")  # Debugging output to check Gini for each feature\n",
    "        if gini_split < best_gini:\n",
    "            best_gini = gini_split\n",
    "            best_feature = feature\n",
    "\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b68d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(data, label, max_depth=None, depth=0):\n",
    "    # If the data is pure or max depth is reached, stop splitting\n",
    "    if data[label].nunique() == 1 or (max_depth and depth >= max_depth):\n",
    "        return data[label].mode()[0]  # Return the majority class\n",
    "\n",
    "    # Find the best feature to split on using Gini\n",
    "    best_feature = find_best_split(data, label)\n",
    "\n",
    "    # Create a subtree for each value of the best feature\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    feature_values = data[best_feature].unique()\n",
    "    for value in feature_values:\n",
    "        subset = data[data[best_feature] == value]  # subset where feature equals this value\n",
    "        tree[best_feature][value] = generate_tree(subset, label, max_depth, depth + 1)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa19df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: age, Gini: 0.34285714285714286\n",
      "Feature: income, Gini: 0.44047619047619047\n",
      "Feature: student, Gini: 0.3673469387755103\n",
      "Feature: credit_rating, Gini: 0.42857142857142855\n",
      "Feature: age, Gini: 0.48\n",
      "Feature: income, Gini: 0.2\n",
      "Feature: student, Gini: 0.0\n",
      "Feature: credit_rating, Gini: 0.4666666666666667\n",
      "Feature: age, Gini: 0.48\n",
      "Feature: income, Gini: 0.4666666666666667\n",
      "Feature: student, Gini: 0.4666666666666667\n",
      "Feature: credit_rating, Gini: 0.0\n",
      "{'age': {'youth': {'student': {'no': 'no', 'yes': 'yes'}}, 'middle_aged': 'yes', 'senior': {'credit_rating': {'fair': 'yes', 'excellent': 'no'}}}}\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your dataset (train_data_m, and the label 'Class: buys_computer')\n",
    "tree = generate_tree(train_data_m, 'buys_computer')\n",
    "print(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4c0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
